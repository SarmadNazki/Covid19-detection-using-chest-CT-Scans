{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "level-magnet",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_obtain_input_shape' from 'keras.applications.imagenet_utils' (C:\\Users\\Sarmad Nazki\\anaconda3\\lib\\site-packages\\keras\\applications\\imagenet_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-dae8fc6b8f81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_squeezenet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSqueezeNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_applications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimagenet_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_squeezenet\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_squeezenet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueezenet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSqueezeNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_squeezenet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_squeezenet\\squeezenet.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimagenet_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_obtain_input_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_obtain_input_shape' from 'keras.applications.imagenet_utils' (C:\\Users\\Sarmad Nazki\\anaconda3\\lib\\site-packages\\keras\\applications\\imagenet_utils.py)"
     ]
    }
   ],
   "source": [
    "#required libraries\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model, Sequential, Input, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras_squeezenet import SqueezeNet\n",
    "from keras_applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "talented-jason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "0\n",
      "COVID\n",
      "************\n",
      "CT\n",
      "************\n",
      "desktop.ini\n",
      "************\n",
      "1\n",
      "non-COVID\n",
      "************\n",
      "CT\n",
      "************\n",
      "desktop.ini\n"
     ]
    }
   ],
   "source": [
    "#create a list in which we can add two values covid and non covid\n",
    "data_train = []\n",
    "type_of_disease =['COVID', 'non-COVID']\n",
    "data_directory = r\"C:\\Users\\Sarmad Nazki\\Desktop\\COVID-19 Dataset\"\n",
    "train_directory = os.path.join(data_directory)\n",
    "\n",
    "for id, sp in enumerate(type_of_disease):\n",
    "    print('************')\n",
    "    print(id)\n",
    "    print(sp)\n",
    "    for file in os.listdir(os.path.join(train_directory )):\n",
    "        print('************')\n",
    "        print(file)\n",
    "        \n",
    "        data_train.append(['{}/{}'.format(sp, file), id, sp])\n",
    "        \n",
    "train = pd.DataFrame(data_train, columns=['Image', 'Id of Disease','Type of Disease'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "operational-punch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id of Disease</th>\n",
       "      <th>Type of Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID/CT</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID/desktop.ini</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-COVID/CT</td>\n",
       "      <td>1</td>\n",
       "      <td>non-COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-COVID/desktop.ini</td>\n",
       "      <td>1</td>\n",
       "      <td>non-COVID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Image  Id of Disease Type of Disease\n",
       "0               COVID/CT              0           COVID\n",
       "1      COVID/desktop.ini              0           COVID\n",
       "2           non-COVID/CT              1       non-COVID\n",
       "3  non-COVID/desktop.ini              1       non-COVID"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check your dataframe which can be developed\n",
    "train.head()\n",
    "#Training model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "polyphonic-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the order of training set randomize\n",
    "SEED = 42\n",
    "train = train.sample(frac=1, random_state=SEED)\n",
    "train.index = np.arange(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "disciplinary-ghost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id of Disease</th>\n",
       "      <th>Type of Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID/desktop.ini</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non-COVID/desktop.ini</td>\n",
       "      <td>1</td>\n",
       "      <td>non-COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID/CT</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-COVID/CT</td>\n",
       "      <td>1</td>\n",
       "      <td>non-COVID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Image  Id of Disease Type of Disease\n",
       "0      COVID/desktop.ini              0           COVID\n",
       "1  non-COVID/desktop.ini              1       non-COVID\n",
       "2               COVID/CT              0           COVID\n",
       "3           non-COVID/CT              1       non-COVID"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "royal-repository",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking with plot to understand the frequency of histogram \n",
    "plt.hist(train['Id of Disease'],color = \"red\")\n",
    "plt.title('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "noticed-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function which shows the images of the covid\n",
    "\n",
    "#def show_covid_images(disease_type, r, c):\n",
    "    #fig,ax = plt.subplots(r,c, figsize=(10,10))\n",
    "    #disease_image = train['Image'][train['Type of Disease'] == disease_type].values\n",
    "    #n = 0\n",
    "    #for i in range(r):\n",
    "        #for j in range(c):\n",
    "            #image = os.path.join(data_directory, disease_image[n])\n",
    "            #ax[i, j].set_xticks([])\n",
    "            #ax[i, j].set_yticks([])\n",
    "            #ax[i, j].imshow(cv2.imread(image))\n",
    "            #n += 1\n",
    "            \n",
    "#show_covid_images('COVID',4,4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function which shows non-covid images\n",
    "#def show_non_covid_images(disease_type, r, c):\n",
    "    #fig,ax = plt.subplots(r,c, figsize=(10,10))\n",
    "    #disease_image = train['Image'][train['Type of Disease'] == disease_type].values\n",
    "    #n = 0\n",
    "    #for i in range(r):\n",
    "        #for j in range(c):\n",
    "            #image = os.path.join(data_directory, disease_image[n])\n",
    "            #ax[i, j].set_xticks([])\n",
    "            #ax[i, j].set_yticks([])\n",
    "            #ax[i, j].imshow(cv2.imread(image))\n",
    "            #n += 1\n",
    "            \n",
    "#show_non_covid_images('non-COVID',4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_OF_IMAGE = 64\n",
    "def read_image(imagepath):\n",
    "    return cv2.imread(os.path.join(data_directory, imagepath))\n",
    "\n",
    "def resize_image(image, image_Size):\n",
    "    return cv2.resize(image.copy(), image_Size, interpolation=cv2.INTER_AREA)     \n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "lightweight-arrangement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 4142.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#training images\n",
    "\n",
    "x_train = np.zeros((train.shape[0], SIZE_OF_IMAGE, SIZE_OF_IMAGE, 3))\n",
    "\n",
    "for i, file in tqdm(enumerate(train['Image'].values)):\n",
    "    image = read_image(file)\n",
    "    \n",
    "    if image is not None:\n",
    "        x_train[i] = resize_image(image,(SIZE_OF_IMAGE, SIZE_OF_IMAGE))\n",
    "        \n",
    "X_Train = x_train / 255\n",
    "print('Train shape: {}'.format(X_Train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "coordinated-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conerting labels to Categorical\n",
    "y_train = train['Id of Disease'].values\n",
    "y_train = to_categorical(y_train, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "positive-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and tes splitting\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Train,y_train, test_size=0.2, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "democratic-blend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training_images\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,15))\n",
    "for i in range(3):\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].imshow(X_train[i])\n",
    "    ax[i].set_title(type_of_disease[np.argmax(Y_train[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "basic-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "SIZE=64\n",
    "N_ch=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "crucial-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeNet \n",
    "\n",
    "def SqueezeNet(include_top=True, weights='imagenet',\n",
    "               input_tensor=None, input_shape=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    \"\"\"Instantiates the SqueezeNet architecture.\n",
    "    \"\"\"\n",
    "        \n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=227,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "\n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    if include_top:\n",
    "        # It's not obvious where to cut the network... \n",
    "        # Could do the 8th or 9th layer... some work recommends cutting earlier layers.\n",
    "    \n",
    "        x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "        x = Activation('relu', name='relu_conv10')(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Activation('softmax', name='loss')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling=='max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "        elif pooling==None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"Unknown argument for 'pooling'=\" + pooling)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name='squeezenet')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "            \n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-logic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-welcome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-preserve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-reviewer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
